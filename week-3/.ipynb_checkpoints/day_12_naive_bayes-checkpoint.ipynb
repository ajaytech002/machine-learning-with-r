{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook is copyright &copy; of <a href=\"https://ajaytech.co\"> Ajay Tech </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is Naive Bayes\n",
    "- Bayes Theorem & Conditional Probability\n",
    "- Naive Bayes Theorem\n",
    "- Example - Classify Fruits based on characteristics\n",
    "- Example - Classify Messages as Spam or Ham\n",
    "  - Get dataset\n",
    "  - EDA\n",
    "  - Simple data engineering\n",
    "  - Sparse Matrix format\n",
    "  - What is a Corpus\n",
    "  - Training and test datasets\n",
    "  - Data modeling\n",
    "  - Verify results\n",
    "- Challenge - Classify Congressman as Democrat or Republican\n",
    "- Naive Bayes on Continuous variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you get an email like so,\n",
    "\n",
    "**From** : njlotterries1234@gmail.com <br>\n",
    "**Subject** : You won Lottery <br>\n",
    "**Body** : Congratulations !!! You won a lottery of 5 Million dollars. Click here to claim.. <br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of this ? Is this a spam e-mail or not ? In all probability this is spam. How do you know it ? Well, you look at the index words - words like \"lottery\" , \"viagra\" , \"free\", \"money back\". When you see these words, generally you tend to classify that message as spam. This is exactly how Naive Bayes works. Let's formalize our understanding a bit by going a bit deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem & Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into \"Naive\" Bayes, we have to first understand **Bayes** theorem. To understand Bayes theorem, we have to first understand something called _Conditional Probability_. What exactly is it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say there is a standard deck of cards and you draw a card at random. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the probability that it is a red card ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/probability_red_card.png\" style=\"background:white\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the probability that it is a face card, given that it is a red card ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/probability_red_card_face_card.png\" style=\"background:white\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called conditional probability. Bayes theorem is an alternate way to compute the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/bayes_formula.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate each one of these probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability of face card P(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/probability_face_card.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability of a red card\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_red.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability of a red card , given it is a face card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_red_face.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And finally, we calculate the probability of a face card, given its a red card P ( face | red )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_face_red.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we achieve here ? Looks like we have made things more complicated, right ? I agree with you. In fact, this formula is not all that useful in machine learning. But there is an assumption that makes this formula extraordinarily useful in ML. Let's go back to the email example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_spam.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not very useful. To calculate the probability of \"You won lottery\" is very arbitrary. You cannot calculate the probability of occurrence of all different phrases or combination of words. The next time around / the subject line might say \"Congratulations!! You won lottery\" -which is slightly different from ' 'You won lottery\" . Point being, you cannot possibly Calculate all different combination of words that could result from the use of all different words in the English dictionary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the Bayes theorem becomes **Naive** . Let's revisit the formula again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_spam_revisirt.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the word \"You\" occurring in the email is independent of the Lord ' \"Won\" occurring. eg.,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you have the paper with **you** ?\n",
    "- we have won the **contract**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Sentences are completely independent. When we break down the event into the respective independent events, probability can be Simplified as follows. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_you_won_lottery.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually a \"Naive\" assumption - because in reality, there is some level of overlap. Meaning, when you mention the word \"lottery\", you almost always use the word \"win\" or some variant-like ''won'\" or \"winning\" . However, this is where ML is lucky. Even with the naive assumption, results are pretty good with text classification in real life. Let's apply the simplification to the Bayes theorem once again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_spam_revisit.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a bit of naivety, this formula became so much more useful. In fact, it makes it so useful that Naive Bayes is almost exclusively used for most text classification tasks. Let's explore this example with some rough data - just believable, made-up data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability of \"You won lottery\" being spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/data_made_up.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability of \"You won spam\" as NOT spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/you_won_lottery_not_spam.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the probability of this phrase not being spam is 1.51. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_not_spam_vs_spam.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty effective, right? Especially given the simplification. Calculating the probability of the individual words is easy. The heart of this algorithm is, given any sentence, this algorithm can break it down into it's components (words) and based on the \"spamminess\" of each of the words, the entire sentence can be classified as spam or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we are trying to do in Naive Bayes, is to break down a complicated problem into its components. Once the component is classified, essentially the bigger piece is classified as well.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is like solving a jigsaw puzzle. How do you solve one typically ? You look for smaller puzzles to solve. Say this is a picture of a car - you start to look for smaller components of the car, like a tire, a windshield and solve for each of these separately. Once you got the pieces figured out, all you have to do is to put them in order. Naive Bayes works more or less like this.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/solve_jigsaw_puzzle.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify fruits based on Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the basics of Naive Bayes, let's create a simple dataset and solve it in excel. The purpose behind this exercise is to get familiar with Naive Bayes calculation using a smaller dataset. This is going to solidify our understanding a bit further, before we dive into more complicated examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/fruits_characteristics.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the fruits dataset in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P_{apple} = 3/9 = 0.333$ <br>\n",
    "$P_{grape} = 3/9 = 0.333$ <br>\n",
    "$P_{melon} = 3/9 = 0.333$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of each of the characteristics - round, large, small etc, can be calculated as below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_round_large.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move on to the individual conditional probabilities. For example, what is the probability that a fruit is round, given that it is an apple ? In all the cases of Apple, the fruit is always round.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_round_apple.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what is the probability that a fruit is red, given that its an apple ? one out of three apples are red.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/red_apple.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like that, we keep calculating the conditional probabilities of all the individual characteristics. Think of this like calculating the probability of each individual word being spam or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/all_3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to test our data. Let's say, we want to calculate the probability of a fruit being an Apple, if it is round and large. All we have to do is plug the numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_apple_round_large.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that a fruit is an apple, if it is round, large and smooth ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_apple_round_large_smooth.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our little dataset, we are not doing too bad. let's do the opposite now. What is the probability of a fruit being a grape, given that it is round, large and smooth ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/p_grape_round_large_smooth_green.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense, right ? grape is never \"large\". Hence the probability of a fruit being a grape if it is \"large\" is relatively small - 16 %.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve the fruits dataset in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "\n",
    "fruits = read.csv(\"./data/fruits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 9 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>fruit</th><th scope=col>round</th><th scope=col>large</th><th scope=col>small</th><th scope=col>red</th><th scope=col>green</th><th scope=col>black</th><th scope=col>golden</th><th scope=col>yellow</th><th scope=col>smooth</th><th scope=col>rough</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>apple</td><td>yes</td><td>yes</td><td>no </td><td>yes</td><td>no </td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>apple</td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>yes</td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>apple</td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>grape</td><td>yes</td><td>no </td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>grape</td><td>yes</td><td>no </td><td>yes</td><td>no </td><td>yes</td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>grape</td><td>yes</td><td>no </td><td>yes</td><td>no </td><td>no </td><td>yes</td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>melon</td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>yes</td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td></tr>\n",
       "\t<tr><td>melon</td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td><td>no </td><td>yes</td></tr>\n",
       "\t<tr><td>melon</td><td>yes</td><td>yes</td><td>no </td><td>no </td><td>no </td><td>no </td><td>no </td><td>yes</td><td>no </td><td>yes</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 9 × 11\n",
       "\\begin{tabular}{lllllllllll}\n",
       " fruit & round & large & small & red & green & black & golden & yellow & smooth & rough\\\\\n",
       " <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t apple & yes & yes & no  & yes & no  & no  & no  & no  & yes & no \\\\\n",
       "\t apple & yes & yes & no  & no  & yes & no  & no  & no  & yes & no \\\\\n",
       "\t apple & yes & yes & no  & no  & no  & no  & yes & no  & yes & no \\\\\n",
       "\t grape & yes & no  & yes & yes & no  & no  & no  & no  & yes & no \\\\\n",
       "\t grape & yes & no  & yes & no  & yes & no  & no  & no  & yes & no \\\\\n",
       "\t grape & yes & no  & yes & no  & no  & yes & no  & no  & yes & no \\\\\n",
       "\t melon & yes & yes & no  & no  & yes & no  & no  & no  & yes & no \\\\\n",
       "\t melon & yes & yes & no  & no  & no  & no  & yes & no  & no  & yes\\\\\n",
       "\t melon & yes & yes & no  & no  & no  & no  & no  & yes & no  & yes\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 9 × 11\n",
       "\n",
       "| fruit &lt;fct&gt; | round &lt;fct&gt; | large &lt;fct&gt; | small &lt;fct&gt; | red &lt;fct&gt; | green &lt;fct&gt; | black &lt;fct&gt; | golden &lt;fct&gt; | yellow &lt;fct&gt; | smooth &lt;fct&gt; | rough &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| apple | yes | yes | no  | yes | no  | no  | no  | no  | yes | no  |\n",
       "| apple | yes | yes | no  | no  | yes | no  | no  | no  | yes | no  |\n",
       "| apple | yes | yes | no  | no  | no  | no  | yes | no  | yes | no  |\n",
       "| grape | yes | no  | yes | yes | no  | no  | no  | no  | yes | no  |\n",
       "| grape | yes | no  | yes | no  | yes | no  | no  | no  | yes | no  |\n",
       "| grape | yes | no  | yes | no  | no  | yes | no  | no  | yes | no  |\n",
       "| melon | yes | yes | no  | no  | yes | no  | no  | no  | yes | no  |\n",
       "| melon | yes | yes | no  | no  | no  | no  | yes | no  | no  | yes |\n",
       "| melon | yes | yes | no  | no  | no  | no  | no  | yes | no  | yes |\n",
       "\n"
      ],
      "text/plain": [
       "  fruit round large small red green black golden yellow smooth rough\n",
       "1 apple yes   yes   no    yes no    no    no     no     yes    no   \n",
       "2 apple yes   yes   no    no  yes   no    no     no     yes    no   \n",
       "3 apple yes   yes   no    no  no    no    yes    no     yes    no   \n",
       "4 grape yes   no    yes   yes no    no    no     no     yes    no   \n",
       "5 grape yes   no    yes   no  yes   no    no     no     yes    no   \n",
       "6 grape yes   no    yes   no  no    yes   no     no     yes    no   \n",
       "7 melon yes   yes   no    no  yes   no    no     no     yes    no   \n",
       "8 melon yes   yes   no    no  no    no    yes    no     no     yes  \n",
       "9 melon yes   yes   no    no  no    no    no     yes    no     yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naiveBayes(fruit ~ . , data = fruits)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict ( model , fruits[,2:11 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>apple</li><li>apple</li><li>apple</li><li>grape</li><li>grape</li><li>grape</li><li>apple</li><li>melon</li><li>melon</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'apple'</li><li>'grape'</li><li>'melon'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item apple\n",
       "\\item apple\n",
       "\\item apple\n",
       "\\item grape\n",
       "\\item grape\n",
       "\\item grape\n",
       "\\item apple\n",
       "\\item melon\n",
       "\\item melon\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'apple'\n",
       "\\item 'grape'\n",
       "\\item 'melon'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. apple\n",
       "2. apple\n",
       "3. apple\n",
       "4. grape\n",
       "5. grape\n",
       "6. grape\n",
       "7. apple\n",
       "8. melon\n",
       "9. melon\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'apple'\n",
       "2. 'grape'\n",
       "3. 'melon'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] apple apple apple grape grape grape apple melon melon\n",
       "Levels: apple grape melon"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "pred    apple grape melon\n",
       "  apple     3     0     1\n",
       "  grape     0     3     0\n",
       "  melon     0     0     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pred, fruits[,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad, given such a small set of characteristics. Let's actually get the confusion matrix to get the accuracy percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction apple grape melon\n",
       "     apple     3     0     1\n",
       "     grape     0     3     0\n",
       "     melon     0     0     2\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.8889          \n",
       "                 95% CI : (0.5175, 0.9972)\n",
       "    No Information Rate : 0.3333          \n",
       "    P-Value [Acc > NIR] : 0.0009653       \n",
       "                                          \n",
       "                  Kappa : 0.8333          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: apple Class: grape Class: melon\n",
       "Sensitivity                1.0000       1.0000       0.6667\n",
       "Specificity                0.8333       1.0000       1.0000\n",
       "Pos Pred Value             0.7500       1.0000       1.0000\n",
       "Neg Pred Value             1.0000       1.0000       0.8571\n",
       "Prevalence                 0.3333       0.3333       0.3333\n",
       "Detection Rate             0.3333       0.3333       0.2222\n",
       "Detection Prevalence       0.4444       0.3333       0.2222\n",
       "Balanced Accuracy          0.9167       1.0000       0.8333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "\n",
    "cm = confusionMatrix(pred,as.factor(fruits[,1]))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an accuracy of almost 90%. We are not very far off, given our dataset is pretty small. The one place where we went wrong is in classify a melon wrongly as an apple. If we compared the predictions vs the actuals, we can see that we went wrong with the 7th entry ( a melon being mis-classified as an apple )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 9 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>predict</th><th scope=col>actual</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>apple</td><td>apple</td></tr>\n",
       "\t<tr><td>apple</td><td>apple</td></tr>\n",
       "\t<tr><td>apple</td><td>apple</td></tr>\n",
       "\t<tr><td>grape</td><td>grape</td></tr>\n",
       "\t<tr><td>grape</td><td>grape</td></tr>\n",
       "\t<tr><td>grape</td><td>grape</td></tr>\n",
       "\t<tr><td>apple</td><td>melon</td></tr>\n",
       "\t<tr><td>melon</td><td>melon</td></tr>\n",
       "\t<tr><td>melon</td><td>melon</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 9 × 2\n",
       "\\begin{tabular}{ll}\n",
       " predict & actual\\\\\n",
       " <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t apple & apple\\\\\n",
       "\t apple & apple\\\\\n",
       "\t apple & apple\\\\\n",
       "\t grape & grape\\\\\n",
       "\t grape & grape\\\\\n",
       "\t grape & grape\\\\\n",
       "\t apple & melon\\\\\n",
       "\t melon & melon\\\\\n",
       "\t melon & melon\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 9 × 2\n",
       "\n",
       "| predict &lt;fct&gt; | actual &lt;fct&gt; |\n",
       "|---|---|\n",
       "| apple | apple |\n",
       "| apple | apple |\n",
       "| apple | apple |\n",
       "| grape | grape |\n",
       "| grape | grape |\n",
       "| grape | grape |\n",
       "| apple | melon |\n",
       "| melon | melon |\n",
       "| melon | melon |\n",
       "\n"
      ],
      "text/plain": [
       "  predict actual\n",
       "1 apple   apple \n",
       "2 apple   apple \n",
       "3 apple   apple \n",
       "4 grape   grape \n",
       "5 grape   grape \n",
       "6 grape   grape \n",
       "7 apple   melon \n",
       "8 melon   melon \n",
       "9 melon   melon "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict = pred\n",
    "actual = fruits[,1]\n",
    "\n",
    "data.frame(predict,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the actual entry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/entries_comparision.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the entry for melon ( watermelon ) coincides in its data points to the green apple. How could this happen ? This is because of an oversimplification with regards to size. We only have 2 sizes - small and large. However, both the apple and water melon are large ( and round and smooth ). And that's why the NB algorithm got it wrong. If we had an extra size characteristic ( say XL ), that would have solved this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify messages as Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understood the basics of Naive Bayes along with a simple example in excel and R, we can proceed to solve the problem that we started with - To classify a message as spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** - Get the dataset <br>\n",
    "There is a simple SMS ( text message ) dataset available at <a href=\"https://www.kaggle.com/uciml/sms-spam-collection-dataset\">kaggle</a> or at the <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\">UCI ML datesets</a>. You can also download the file from <a href=\"https://github.com/ajaytech002/DataScience_Python/blob/master/week_3_ml_algorithms/data/spam.csv\">Ajay Tech's github page</a>.  Download the zip file and open it in excel as a tab delimited format. Each of these messages have been classified as either spam or ham ( ham is just a technical word for \"non-spam\" ). Open the dataset in excel as a tab-delimited format and give column names ( if not available already ).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** - Read the dataset into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(\"./data/spam.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>class</th><th scope=col>message</th><th scope=col>X</th><th scope=col>X.1</th><th scope=col>X.2</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>ham </td><td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            </td><td></td><td></td><td></td></tr>\n",
       "\t<tr><th scope=row>2</th><td>ham </td><td>Ok lar... Joking wif u oni...                                                                                                                              </td><td></td><td></td><td></td></tr>\n",
       "\t<tr><th scope=row>3</th><td>spam</td><td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td><td></td><td></td><td></td></tr>\n",
       "\t<tr><th scope=row>4</th><td>ham </td><td>U dun say so early hor... U c already then say...                                                                                                          </td><td></td><td></td><td></td></tr>\n",
       "\t<tr><th scope=row>5</th><td>ham </td><td>Nah I don't think he goes to usf, he lives around here though                                                                                              </td><td></td><td></td><td></td></tr>\n",
       "\t<tr><th scope=row>6</th><td>spam</td><td>FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv        </td><td></td><td></td><td></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & class & message & X & X.1 & X.2\\\\\n",
       "  & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & ham  & Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                             &  &  & \\\\\n",
       "\t2 & ham  & Ok lar... Joking wif u oni...                                                                                                                               &  &  & \\\\\n",
       "\t3 & spam & Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T\\&C's apply 08452810075over18's &  &  & \\\\\n",
       "\t4 & ham  & U dun say so early hor... U c already then say...                                                                                                           &  &  & \\\\\n",
       "\t5 & ham  & Nah I don't think he goes to usf, he lives around here though                                                                                               &  &  & \\\\\n",
       "\t6 & spam & FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv         &  &  & \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | class &lt;fct&gt; | message &lt;fct&gt; | X &lt;fct&gt; | X.1 &lt;fct&gt; | X.2 &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | ham  | Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                             | <!----> | <!----> | <!----> |\n",
       "| 2 | ham  | Ok lar... Joking wif u oni...                                                                                                                               | <!----> | <!----> | <!----> |\n",
       "| 3 | spam | Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's | <!----> | <!----> | <!----> |\n",
       "| 4 | ham  | U dun say so early hor... U c already then say...                                                                                                           | <!----> | <!----> | <!----> |\n",
       "| 5 | ham  | Nah I don't think he goes to usf, he lives around here though                                                                                               | <!----> | <!----> | <!----> |\n",
       "| 6 | spam | FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv         | <!----> | <!----> | <!----> |\n",
       "\n"
      ],
      "text/plain": [
       "  class\n",
       "1 ham  \n",
       "2 ham  \n",
       "3 spam \n",
       "4 ham  \n",
       "5 ham  \n",
       "6 spam \n",
       "  message                                                                                                                                                    \n",
       "1 Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            \n",
       "2 Ok lar... Joking wif u oni...                                                                                                                              \n",
       "3 Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
       "4 U dun say so early hor... U c already then say...                                                                                                          \n",
       "5 Nah I don't think he goes to usf, he lives around here though                                                                                              \n",
       "6 FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv        \n",
       "  X X.1 X.2\n",
       "1          \n",
       "2          \n",
       "3          \n",
       "4          \n",
       "5          \n",
       "6          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[,c(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>class</th><th scope=col>message</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>ham </td><td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>ham </td><td>Ok lar... Joking wif u oni...                                                                                                                              </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>spam</td><td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>ham </td><td>U dun say so early hor... U c already then say...                                                                                                          </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>ham </td><td>Nah I don't think he goes to usf, he lives around here though                                                                                              </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>spam</td><td>FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & class & message\\\\\n",
       "  & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & ham  & Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            \\\\\n",
       "\t2 & ham  & Ok lar... Joking wif u oni...                                                                                                                              \\\\\n",
       "\t3 & spam & Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T\\&C's apply 08452810075over18's\\\\\n",
       "\t4 & ham  & U dun say so early hor... U c already then say...                                                                                                          \\\\\n",
       "\t5 & ham  & Nah I don't think he goes to usf, he lives around here though                                                                                              \\\\\n",
       "\t6 & spam & FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | class &lt;fct&gt; | message &lt;fct&gt; |\n",
       "|---|---|---|\n",
       "| 1 | ham  | Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                             |\n",
       "| 2 | ham  | Ok lar... Joking wif u oni...                                                                                                                               |\n",
       "| 3 | spam | Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's |\n",
       "| 4 | ham  | U dun say so early hor... U c already then say...                                                                                                           |\n",
       "| 5 | ham  | Nah I don't think he goes to usf, he lives around here though                                                                                               |\n",
       "| 6 | spam | FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv         |\n",
       "\n"
      ],
      "text/plain": [
       "  class\n",
       "1 ham  \n",
       "2 ham  \n",
       "3 spam \n",
       "4 ham  \n",
       "5 ham  \n",
       "6 spam \n",
       "  message                                                                                                                                                    \n",
       "1 Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            \n",
       "2 Ok lar... Joking wif u oni...                                                                                                                              \n",
       "3 Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
       "4 U dun say so early hor... U c already then say...                                                                                                          \n",
       "5 Nah I don't think he goes to usf, he lives around here though                                                                                              \n",
       "6 FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** - Simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many messages are there in the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5572"
      ],
      "text/latex": [
       "5572"
      ],
      "text/markdown": [
       "5572"
      ],
      "text/plain": [
       "[1] 5572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out of them, count the occurances of spam vs ham(non-spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>ham</dt><dd>4825</dd><dt>spam</dt><dd>747</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[ham] 4825\n",
       "\\item[spam] 747\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "ham\n",
       ":   4825spam\n",
       ":   747\n",
       "\n"
      ],
      "text/plain": [
       " ham spam \n",
       "4825  747 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of this is spam ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>spam:</strong> 15.4818652849741"
      ],
      "text/latex": [
       "\\textbf{spam:} 15.4818652849741"
      ],
      "text/markdown": [
       "**spam:** 15.4818652849741"
      ],
      "text/plain": [
       "    spam \n",
       "15.48187 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data$class)[\"spam\"] / summary(data$class)[\"ham\"] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 % of the messages are spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we converted the fruits dataset's feature values from \"yes\" or \"no\" to a 1 or 0 , Naive Bayes (or for that matter most ML algorithms) need the feature data to be numeric in nature. In order to do it, we have to use some techniques from Natural language processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize the message (into words) and create a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process basically splits the sentence (message) to it's individual words. Let's see a sample before we tokenize the entire dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/sparse-matrix-example.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same on our real messages dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<SimpleCorpus>>\n",
      "Metadata:  corpus specific: 1, document level (indexed): 0\n",
      "Content:  documents: 5572\n"
     ]
    }
   ],
   "source": [
    "library(tm)\n",
    "message_corpus = Corpus(VectorSource(data$message))\n",
    "print ( message_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_dtm <- DocumentTermMatrix(message_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document term matrix (DTM) is in a binary format. So, we can't just print it out using indices. Instead, we use the **inspect ( )** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<DocumentTermMatrix (documents: 10, terms: 20)>>\n",
      "Non-/sparse entries: 21/179\n",
      "Sparsity           : 90%\n",
      "Maximal term length: 19\n",
      "Weighting          : term frequency (tf)\n",
      "Sample             :\n",
      "    Terms\n",
      "Docs amore available buffet... bugis cine crazy.. got great jurong there\n",
      "  1      1         1         1     1    1       1   1     1      1     1\n",
      "  10     0         0         0     0    0       0   0     0      0     0\n",
      "  2      0         0         0     0    0       0   0     0      0     0\n",
      "  3      0         0         0     0    0       0   0     0      0     0\n",
      "  4      0         0         0     0    0       0   0     0      0     0\n",
      "  5      0         0         0     0    0       0   0     0      0     0\n",
      "  6      0         0         0     0    0       0   0     0      0     1\n",
      "  7      0         0         0     0    0       0   0     0      0     0\n",
      "  8      0         0         0     0    0       0   0     0      0     0\n",
      "  9      0         0         0     0    0       0   0     0      0     0\n"
     ]
    }
   ],
   "source": [
    "inspect(message_dtm[1:10,1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** - Train/Test data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the DTM as-is, we have to convert the 0,1's to Factors - like a Yes and No. This is becuase Naive Bayes works well with Factors. Let's write a small functiont that converts all values greater than 0 to a Yes and otherwise to No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_to_factor = function(x){\n",
    "  x = ifelse(x > 0, 1, 0)\n",
    "  x = factor(x, levels = c(0,1), labels = c(\"No\", \"Yes\"))\n",
    "  return (x)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply this function to the DTM, let's split the data into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = sample(1:nrow(data),nrow(data)*.8)\n",
    "train = data[index,2]\n",
    "test = data[-index,2]\n",
    "\n",
    "msg_cor_train      = Corpus(VectorSource(data[train,]$message))\n",
    "msg_train_dtm      = DocumentTermMatrix(msg_cor_train)\n",
    "msg_train_dtm      = apply(msg_train_dtm, MARGIN = 2, counts_to_factor)\n",
    "msg_class_train    = data$class[train]\n",
    "\n",
    "\n",
    "msg_cor_test       = Corpus(VectorSource(data[test,]$message))\n",
    "msg_test_dtm       = DocumentTermMatrix(msg_cor_test)\n",
    "msg_test_dtm       = apply(msg_test_dtm, MARGIN = 2, counts_to_factor)\n",
    "msg_class_test     = data$class[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 5 of type chr</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>2wks</th><th scope=col>87077</th><th scope=col>87077:</th><th scope=col>club</th><th scope=col>free</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>No </td><td>No </td><td>No </td><td>No </td><td>No </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>No </td><td>No </td><td>No </td><td>No </td><td>No </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>No </td><td>No </td><td>No </td><td>No </td><td>No </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>No </td><td>No </td><td>No </td><td>No </td><td>No </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>No </td><td>No </td><td>No </td><td>No </td><td>No </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 5 of type chr\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & 2wks & 87077 & 87077: & club & free\\\\\n",
       "\\hline\n",
       "\t1 & Yes & Yes & Yes & Yes & Yes\\\\\n",
       "\t2 & No  & No  & No  & No  & No \\\\\n",
       "\t3 & No  & No  & No  & No  & No \\\\\n",
       "\t4 & No  & No  & No  & No  & No \\\\\n",
       "\t5 & No  & No  & No  & No  & No \\\\\n",
       "\t6 & No  & No  & No  & No  & No \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 5 of type chr\n",
       "\n",
       "| <!--/--> | 2wks | 87077 | 87077: | club | free |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | Yes | Yes | Yes | Yes | Yes |\n",
       "| 2 | No  | No  | No  | No  | No  |\n",
       "| 3 | No  | No  | No  | No  | No  |\n",
       "| 4 | No  | No  | No  | No  | No  |\n",
       "| 5 | No  | No  | No  | No  | No  |\n",
       "| 6 | No  | No  | No  | No  | No  |\n",
       "\n"
      ],
      "text/plain": [
       "    Terms\n",
       "Docs 2wks 87077 87077: club free\n",
       "   1 Yes  Yes   Yes    Yes  Yes \n",
       "   2 No   No    No     No   No  \n",
       "   3 No   No    No     No   No  \n",
       "   4 No   No    No     No   No  \n",
       "   5 No   No    No     No   No  \n",
       "   6 No   No    No     No   No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(msg_train_dtm[,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train_df = as.data.frame(as.matrix(msg_train_dtm))\n",
    "msg_test_df  = as.data.frame(as.matrix(msg_test_dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 8479</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>been</th><th scope=col>curtsey?</th><th scope=col>have</th><th scope=col>practising</th><th scope=col>you</th><th scope=col>your</th><th scope=col>off.</th><th scope=col>pissed</th><th scope=col>pretty</th><th scope=col>whatever,</th><th scope=col>...</th><th scope=col>not..tel</th><th scope=col>clearer..</th><th scope=col>sections</th><th scope=col>above</th><th scope=col>da..al</th><th scope=col>coins</th><th scope=col>factory</th><th scope=col>chart</th><th scope=col>heroes,</th><th scope=col>tips</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8479\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & been & curtsey? & have & practising & you & your & off. & pissed & pretty & whatever, & ... & not..tel & clearer.. & sections & above & da..al & coins & factory & chart & heroes, & tips\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t2 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t4 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t6 & 0 & 0 & 0 & 0 & 3 & 1 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8479\n",
       "\n",
       "| <!--/--> | been &lt;dbl&gt; | curtsey? &lt;dbl&gt; | have &lt;dbl&gt; | practising &lt;dbl&gt; | you &lt;dbl&gt; | your &lt;dbl&gt; | off. &lt;dbl&gt; | pissed &lt;dbl&gt; | pretty &lt;dbl&gt; | whatever, &lt;dbl&gt; | ... ... | not..tel &lt;dbl&gt; | clearer.. &lt;dbl&gt; | sections &lt;dbl&gt; | above &lt;dbl&gt; | da..al &lt;dbl&gt; | coins &lt;dbl&gt; | factory &lt;dbl&gt; | chart &lt;dbl&gt; | heroes, &lt;dbl&gt; | tips &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 4 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 6 | 0 | 0 | 0 | 0 | 3 | 1 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  been curtsey? have practising you your off. pissed pretty whatever, ...\n",
       "1 1    1        1    1          1   1    0    0      0      0         ...\n",
       "2 0    0        0    0          0   0    1    1      1      1         ...\n",
       "3 0    0        0    0          0   0    0    0      0      0         ...\n",
       "4 0    0        0    0          0   1    0    0      0      0         ...\n",
       "5 0    0        0    0          0   0    0    0      0      0         ...\n",
       "6 0    0        0    0          3   1    0    0      0      0         ...\n",
       "  not..tel clearer.. sections above da..al coins factory chart heroes, tips\n",
       "1 0        0         0        0     0      0     0       0     0       0   \n",
       "2 0        0         0        0     0      0     0       0     0       0   \n",
       "3 0        0         0        0     0      0     0       0     0       0   \n",
       "4 0        0         0        0     0      0     0       0     0       0   \n",
       "5 0        0         0        0     0      0     0       0     0       0   \n",
       "6 0        0         0        0     0      0     0       0     0       0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(msg_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6** - Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "model = naiveBayes(msg_train_dtm, msg_class_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7** - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(model, msg_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              pred\n",
       "msg_class_test ham spam\n",
       "          ham  950   13\n",
       "          spam  18  134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(msg_class_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy using the confusion matrix from the caret library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  ham spam\n",
       "      ham  2385   46\n",
       "      spam   12  343\n",
       "                                          \n",
       "               Accuracy : 0.9792          \n",
       "                 95% CI : (0.9732, 0.9842)\n",
       "    No Information Rate : 0.8604          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.9101          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 1.47e-05        \n",
       "                                          \n",
       "            Sensitivity : 0.9950          \n",
       "            Specificity : 0.8817          \n",
       "         Pos Pred Value : 0.9811          \n",
       "         Neg Pred Value : 0.9662          \n",
       "             Prevalence : 0.8604          \n",
       "         Detection Rate : 0.8561          \n",
       "   Detection Prevalence : 0.8726          \n",
       "      Balanced Accuracy : 0.9384          \n",
       "                                          \n",
       "       'Positive' Class : ham             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "\n",
    "cm = confusionMatrix(pred,msg_class_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is scope for a ton of optimization here like\n",
    "- convert all characters to lower case\n",
    "- remove punctuation\n",
    "- remove stop words \n",
    "etc <br>\n",
    "\n",
    "But that is a subject for another day. Here we will just focus on learning the Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve another problem in Naive Bayes. Load up a dataset called house-votes-84.csv from the data folder. The data set should look like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/house-votes-snapshot.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results from Congressmen in the US, voting a Yes ( for ) or No (Against ) on 16 different issues. Instead of putting names, the class column identifies the congressmen as either a Republican or a Democrat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - Identify the congressmen as either a Democrat or Republican based on his voting pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution** - This problem is almost exactly similar to the fruits data we started with at the beginning of leaning Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Class</th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th><th scope=col>V16</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>republican</td><td>n </td><td>y</td><td>n</td><td>y </td><td>y </td><td>y</td><td>n</td><td>n</td><td>n</td><td>y</td><td>NA</td><td>y </td><td>y</td><td>y</td><td>n</td><td>y </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>republican</td><td>n </td><td>y</td><td>n</td><td>y </td><td>y </td><td>y</td><td>n</td><td>n</td><td>n</td><td>n</td><td>n </td><td>y </td><td>y</td><td>y</td><td>n</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>democrat  </td><td>NA</td><td>y</td><td>y</td><td>NA</td><td>y </td><td>y</td><td>n</td><td>n</td><td>n</td><td>n</td><td>y </td><td>n </td><td>y</td><td>y</td><td>n</td><td>n </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>democrat  </td><td>n </td><td>y</td><td>y</td><td>n </td><td>NA</td><td>y</td><td>n</td><td>n</td><td>n</td><td>n</td><td>y </td><td>n </td><td>y</td><td>n</td><td>n</td><td>y </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>democrat  </td><td>y </td><td>y</td><td>y</td><td>n </td><td>y </td><td>y</td><td>n</td><td>n</td><td>n</td><td>n</td><td>y </td><td>NA</td><td>y</td><td>y</td><td>y</td><td>y </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>democrat  </td><td>n </td><td>y</td><td>y</td><td>n </td><td>y </td><td>y</td><td>n</td><td>n</td><td>n</td><td>n</td><td>n </td><td>n </td><td>y</td><td>y</td><td>y</td><td>y </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       "  & Class & V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & V12 & V13 & V14 & V15 & V16\\\\\n",
       "  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & republican & n  & y & n & y  & y  & y & n & n & n & y & NA & y  & y & y & n & y \\\\\n",
       "\t2 & republican & n  & y & n & y  & y  & y & n & n & n & n & n  & y  & y & y & n & NA\\\\\n",
       "\t3 & democrat   & NA & y & y & NA & y  & y & n & n & n & n & y  & n  & y & y & n & n \\\\\n",
       "\t4 & democrat   & n  & y & y & n  & NA & y & n & n & n & n & y  & n  & y & n & n & y \\\\\n",
       "\t5 & democrat   & y  & y & y & n  & y  & y & n & n & n & n & y  & NA & y & y & y & y \\\\\n",
       "\t6 & democrat   & n  & y & y & n  & y  & y & n & n & n & n & n  & n  & y & y & y & y \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 17\n",
       "\n",
       "| <!--/--> | Class &lt;fct&gt; | V1 &lt;fct&gt; | V2 &lt;fct&gt; | V3 &lt;fct&gt; | V4 &lt;fct&gt; | V5 &lt;fct&gt; | V6 &lt;fct&gt; | V7 &lt;fct&gt; | V8 &lt;fct&gt; | V9 &lt;fct&gt; | V10 &lt;fct&gt; | V11 &lt;fct&gt; | V12 &lt;fct&gt; | V13 &lt;fct&gt; | V14 &lt;fct&gt; | V15 &lt;fct&gt; | V16 &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | republican | n  | y | n | y  | y  | y | n | n | n | y | NA | y  | y | y | n | y  |\n",
       "| 2 | republican | n  | y | n | y  | y  | y | n | n | n | n | n  | y  | y | y | n | NA |\n",
       "| 3 | democrat   | NA | y | y | NA | y  | y | n | n | n | n | y  | n  | y | y | n | n  |\n",
       "| 4 | democrat   | n  | y | y | n  | NA | y | n | n | n | n | y  | n  | y | n | n | y  |\n",
       "| 5 | democrat   | y  | y | y | n  | y  | y | n | n | n | n | y  | NA | y | y | y | y  |\n",
       "| 6 | democrat   | n  | y | y | n  | y  | y | n | n | n | n | n  | n  | y | y | y | y  |\n",
       "\n"
      ],
      "text/plain": [
       "  Class      V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16\n",
       "1 republican n  y  n  y  y  y  n  n  n  y   NA  y   y   y   n   y  \n",
       "2 republican n  y  n  y  y  y  n  n  n  n   n   y   y   y   n   NA \n",
       "3 democrat   NA y  y  NA y  y  n  n  n  n   y   n   y   y   n   n  \n",
       "4 democrat   n  y  y  n  NA y  n  n  n  n   y   n   y   n   n   y  \n",
       "5 democrat   y  y  y  n  y  y  n  n  n  n   y   NA  y   y   y   y  \n",
       "6 democrat   n  y  y  n  y  y  n  n  n  n   n   n   y   y   y   y  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            \n",
       "pred         democrat republican\n",
       "  democrat        121          5\n",
       "  republican       21         71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "            Reference\n",
      "Prediction   democrat republican\n",
      "  democrat        121          5\n",
      "  republican       21         71\n",
      "                                          \n",
      "               Accuracy : 0.8807          \n",
      "                 95% CI : (0.8301, 0.9206)\n",
      "    No Information Rate : 0.6514          \n",
      "    P-Value [Acc > NIR] : 1.002e-14       \n",
      "                                          \n",
      "                  Kappa : 0.7496          \n",
      "                                          \n",
      " Mcnemar's Test P-Value : 0.003264        \n",
      "                                          \n",
      "            Sensitivity : 0.8521          \n",
      "            Specificity : 0.9342          \n",
      "         Pos Pred Value : 0.9603          \n",
      "         Neg Pred Value : 0.7717          \n",
      "             Prevalence : 0.6514          \n",
      "         Detection Rate : 0.5550          \n",
      "   Detection Prevalence : 0.5780          \n",
      "      Balanced Accuracy : 0.8932          \n",
      "                                          \n",
      "       'Positive' Class : democrat        \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "# 1. Import the dataset\n",
    "library(mlbench)\n",
    "\n",
    "data(HouseVotes84, package = \"mlbench\")\n",
    "\n",
    "data = HouseVotes84\n",
    "head(data)\n",
    "\n",
    "# 2. train/test split\n",
    "index = sample(1:nrow(data),nrow(data)*.8)\n",
    "train = data[index,]\n",
    "test = data[-index,]\n",
    "\n",
    "# 3. model the data\n",
    "model = naiveBayes(Class ~ ., data = train)\n",
    "\n",
    "# 4. predict the data\n",
    "pred = predict(model, test)\n",
    "\n",
    "# 5. Accuracy\n",
    "table(pred, test$Class)\n",
    "\n",
    "library(caret)\n",
    "\n",
    "cm = confusionMatrix(pred,test$Class)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - IMDB review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the SPAM/HAM problem, we can also predict if an IMDB review is positive or negative based on the words in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 - Read the data file\n",
    "library(\"xlsx\")\n",
    "data = read.xlsx(\"./data/imdb-reviews-sentiment.xlsx\", sheetIndex = 1,  header=TRUE)\n",
    "\n",
    "# step 2 - Create a DTM based on the text data\n",
    "library(tm)\n",
    "message_corpus = Corpus(VectorSource(data$review))\n",
    "message_dtm <- DocumentTermMatrix(message_corpus)\n",
    "\n",
    "# step 3 - function to convert the integers to \"Yes\" or \"No\" factors in the DTM\n",
    "counts_to_factor = function(x){\n",
    "  x = ifelse(x > 0, 1, 0)\n",
    "  x = factor(x, levels = c(0,1), labels = c(\"No\", \"Yes\"))\n",
    "  return (x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - Split the DTMs to Train and test data and convert the integers to factors for \"Yes\" and \"No\"\n",
    "index = sample(1:nrow(data),nrow(data)*.8)\n",
    "train = data[index,2]\n",
    "test = data[-index,2]\n",
    "\n",
    "msg_cor_train      = Corpus(VectorSource(data[train,]$review))\n",
    "msg_train_dtm      = DocumentTermMatrix(msg_cor_train)\n",
    "msg_train_dtm      = apply(msg_train_dtm, MARGIN = 2, counts_to_factor)\n",
    "msg_class_train    = data$sentiment[train]\n",
    "\n",
    "\n",
    "msg_cor_test       = Corpus(VectorSource(data[test,]$review))\n",
    "msg_test_dtm       = DocumentTermMatrix(msg_cor_test)\n",
    "msg_test_dtm       = apply(msg_test_dtm, MARGIN = 2, counts_to_factor)\n",
    "msg_class_test     = data$sentiment[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - model the data using Naive Bayes\n",
    "library(e1071)\n",
    "model = naiveBayes(msg_train_dtm, msg_class_train)\n",
    "\n",
    "#step 4- predict the results from the model using the test data\n",
    "pred = predict(model, msg_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction negative positive\n",
      "  negative        0        0\n",
      "  positive        0     2000\n",
      "                                     \n",
      "               Accuracy : 1          \n",
      "                 95% CI : (0.9982, 1)\n",
      "    No Information Rate : 1          \n",
      "    P-Value [Acc > NIR] : 1          \n",
      "                                     \n",
      "                  Kappa : NaN        \n",
      "                                     \n",
      " Mcnemar's Test P-Value : NA         \n",
      "                                     \n",
      "            Sensitivity : NA         \n",
      "            Specificity :  1         \n",
      "         Pos Pred Value : NA         \n",
      "         Neg Pred Value : NA         \n",
      "             Prevalence :  0         \n",
      "         Detection Rate :  0         \n",
      "   Detection Prevalence :  0         \n",
      "      Balanced Accuracy : NA         \n",
      "                                     \n",
      "       'Positive' Class : negative   \n",
      "                                     \n"
     ]
    }
   ],
   "source": [
    "# step 6 - get the accuracy from confusion matrix.\n",
    "library(caret)\n",
    "cm = confusionMatrix(pred,data$sentiment[test])\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on continuous variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen Naive Bayes work on factor variables. Does NB ever work on continous variables ? Yes, it does - ofcourse with discretized version of those variables ( Think of binning a normal distribution ). The key assumption there would be that the variable has a normal distribution. For example, think of the iris dataset - is the \"Sepal length\" of setosa species normally distributed ? Let's find out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_data    = iris.data\n",
    "iris_target  = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x147cca70>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib does not have the ability to plot the kernel density function\n",
    "import matplotlib.pyplot as plt\n",
    "# So, we are using seaborn instead\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# You can check from these curves that Sepal data is normally distributed, but\n",
    "# the petal data is not. Try them on one by one.\n",
    "\n",
    "sns.distplot(iris_data[:,0], hist=True, kde=True)\n",
    "sns.distplot(iris_data[:,1], hist=True, kde=True)\n",
    "sns.distplot(iris_data[:,2], hist=True, kde=True)\n",
    "sns.distplot(iris_data[:,3], hist=True, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the Sepal data is normally distributed. Ideally, we should just be using the sepal data ( Sepal Length and Sepal Width ). However, let's just use all of these and see what happens. As an exercise, try using just the sepal data and check for the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0   1   2  All\n",
      "Actual                   \n",
      "0          6   0   0    6\n",
      "1          0  11   1   12\n",
      "2          0   1  11   12\n",
      "All        6  12  12   30\n",
      "[[ 6  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  1 11]]\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 1. train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data , iris_target, test_size=0.2)  \n",
    "\n",
    "# 2. Naive Bayes modeling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "# 3. Predict data\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# 4. Create a confusion matrix to check accuracy\n",
    "print ( pd.crosstab(y_test, y_predict,rownames=['Actual'], colnames=['Predicted'],  margins=True) )\n",
    "\n",
    "# 5. Print the accuracy score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print ( confusion_matrix(y_test, y_predict) )\n",
    "print ( accuracy_score(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty accurate as well , isn't it ? In fact even though one of the assumptions (all the variables should be independent of each other ) is wrong, Naive Bayes still outperforms some other classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The priors ( Probability of a \"Setosa\" occuring or a \"Virginica\" occuring .. ) is 0.33 ( a third ) - which we know.\n",
    "- How about the conditional probabilities ? This is where it gets tricky for continuous variables. You cannot have conditional probabilities for each of the values ( as the number can get infinite ). So, in case of a normal distribution, an approximation is applied based on the following formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/conditional_probability.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where μ is the mean and σ is the variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
